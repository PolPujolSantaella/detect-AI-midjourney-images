{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7eefa98",
   "metadata": {},
   "source": [
    "# Detecting Midjourney Images via Feature Engineering & Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb24925b",
   "metadata": {},
   "source": [
    "**Objectives**\n",
    "\n",
    "- **Engineer Discriminative Features**\n",
    "    Develop and extract features that effectively separate Stable Diffusion (AI-generated) images from authentic camera-captured photos using frequency, color, and texture analysis\n",
    "\n",
    "- **Build Reproducible Pipeline**\n",
    "\n",
    "    Construct a robust feature extraction pipeline that generates a tabular dataset suitable for ML. Ensure consistency and reproducibility across experiments.\n",
    "\n",
    "- **Train & Evaluate Classifiers**\n",
    "\n",
    "    Implement a classifier architectures such as Random Forest, XGBoost, SVM or Neural Networks. Rigorously evaluate performance using industry-standard metrics and confusion matrices\n",
    "\n",
    "- **Quantify Feature Relevance**\n",
    "\n",
    "    Apply multiple interpretability techniques such as Gini importance. Permutation importance, and SHAP values to understand which features drive classification decisions.\n",
    "\n",
    "\n",
    "**Dataset Structure**\n",
    "```bash\n",
    "imagenet_midjourney/\n",
    "|----test/ \n",
    "| |----ai/ \n",
    "| | |--[AI-generated images] (Stable Diffusion/Midjourney) \n",
    "| | Label: 1 (fake) \n",
    "| |----nature/ \n",
    "| | |--[Natural camera images] \n",
    "| | (Non-AI photographs) \n",
    "| | Label: 0 (real)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861f9abb",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7baac7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage import io, color, img_as_ubyte\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy.stats import linregress, gmean, pearsonr, kurtosis\n",
    "\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "\n",
    "DATASET_DIR = \"imagenet_midjourney/test\"\n",
    "\n",
    "CATEGORIES = {\n",
    "    \"ai\": 1,\n",
    "    \"nature\": 0\n",
    "}\n",
    "\n",
    "IMG_SIZE = (256, 256)\n",
    "COLOR_MODE = 'rgb'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c34c2c",
   "metadata": {},
   "source": [
    "## Image Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b150ef53",
   "metadata": {},
   "source": [
    "Load images from dataset directories, normalize formats, and prepare for feature extraction. Handle various input formats consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e64392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_images(base_dir, categories, img_size=(256, 256), color_mode='rgb'):\n",
    "    X, y, paths = [], [], []\n",
    "\n",
    "    for category, label in categories.items():\n",
    "        folder = os.path.join(base_dir, category)\n",
    "        if not os.path.exists(folder):\n",
    "            print(f\"Folder not encountered: {folder}\")\n",
    "            continue\n",
    "\n",
    "        for filename in tqdm(os.listdir(folder), desc=f\"Loading {category}\"):\n",
    "            file_path = os.path.join(folder, filename)\n",
    "\n",
    "            if not filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.webp')):\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                image = io.imread(file_path)\n",
    "\n",
    "                if color_mode == 'rgb':\n",
    "                    if image.ndim == 2:\n",
    "                        image = color.gray2rgb(image)\n",
    "                    elif image.shape[2] == 4:\n",
    "                        image = color.rgba2rgb(image)\n",
    "                elif color_mode == 'gray':\n",
    "                    image = color.rgb2gray(image)\n",
    "\n",
    "                image = cv2.resize(img_as_ubyte(image), img_size)\n",
    "\n",
    "                image = image.astype(np.float32) / 255.0\n",
    "\n",
    "                X.append(image)\n",
    "                y.append(label)\n",
    "                paths.append(file_path)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y, paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e8bfaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading ai: 100%|██████████| 500/500 [00:17<00:00, 28.03it/s]\n",
      "Loading nature: 100%|██████████| 500/500 [00:02<00:00, 196.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total imágenes cargadas: 1000\n",
      "Dimensión de ejemplo: (256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "X, y, image_paths = load_and_preprocess_images(DATASET_DIR, CATEGORIES, IMG_SIZE, COLOR_MODE)\n",
    "\n",
    "print(f\"Total imágenes cargadas: {len(X)}\")\n",
    "print(f\"Dimensión de ejemplo: {X[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e11400",
   "metadata": {},
   "source": [
    "## Feature Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca318ba",
   "metadata": {},
   "source": [
    "Extract per-image features across frequency, color, and texture domains. Generate comprehensive feature vectors for each sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51269539",
   "metadata": {},
   "source": [
    "### Feature Family I: Frequency & Spectrum Analysis (FFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9aee6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fft_features(image):\n",
    "    gray = cv2.cvtColor((image * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "    gray = gray.astype(np.float32) / 255.0\n",
    "\n",
    "    fft2 = np.fft.fft2(gray)\n",
    "    fshift = np.fft.fftshift(fft2)\n",
    "    magnitude_spectrum = np.abs(fshift) ** 2\n",
    "\n",
    "    rows, cols = gray.shape\n",
    "    crow, ccol = rows // 2, cols // 2\n",
    "    y, x = np.ogrid[:rows, :cols]\n",
    "    radius = np.sqrt((x - ccol) ** 2 + (y - crow) ** 2).astype(np.int32)\n",
    "\n",
    "    radial_profile = np.bincount(radius.ravel(), magnitude_spectrum.ravel()) / np.bincount(radius.ravel())\n",
    "    radial_profile = radial_profile[1:]\n",
    "\n",
    "    radial_power_spectrum_mean = np.mean(radial_profile)\n",
    "\n",
    "    freqs = np.arange(1, len(radial_profile) + 1)\n",
    "    log_freqs = np.log(freqs)\n",
    "    log_power = np.log(radial_profile + 1e-8)\n",
    "    slope, intercept, _, _, _ = linregress(log_freqs, log_power)\n",
    "    spectral_slope = slope\n",
    "\n",
    "    spectral_flatness = gmean(radial_profile + 1e-8) / (np.mean(radial_profile) + 1e-8)\n",
    "\n",
    "    cutoff = len(radial_profile) // 3\n",
    "    high_freq_energy = np.sum(radial_profile[-cutoff:])\n",
    "    total_energy = np.sum(radial_profile)\n",
    "    high_freq_ratio = high_freq_energy / (total_energy + 1e-8)\n",
    "\n",
    "    return {\n",
    "        'radial_power_spectrum_mean': radial_power_spectrum_mean,\n",
    "        'spectral_slope': spectral_slope,\n",
    "        'spectral_flatness': spectral_flatness,\n",
    "        'high_freq_ratio': high_freq_ratio\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b6f555",
   "metadata": {},
   "source": [
    "### Feature Family II: Colo & Chrominance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33cf45a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_pearsonr(a, b):\n",
    "    if np.std(a) < 1e-8 or np.std(b) < 1e-8:\n",
    "        return 0.0\n",
    "    r, _ = pearsonr(a, b)\n",
    "    return np.nan_to_num(r, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "def safe_kurtosis(x):\n",
    "    if x.size == 0 or np.allclose(x, x.flat[0], atol=1e-8) or np.std(x) < 1e-8:\n",
    "        return 0.0\n",
    "    val = kurtosis(x, fisher=False)\n",
    "    return np.nan_to_num(val, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "def compute_color_features(image):\n",
    "    img_8bit = (image * 255).astype(np.uint8)\n",
    "\n",
    "    R = img_8bit[:, :, 0].astype(np.float32).ravel()\n",
    "    G = img_8bit[:, :, 1].astype(np.float32).ravel()\n",
    "    B = img_8bit[:, :, 2].astype(np.float32).ravel()\n",
    "\n",
    "    corr_rg = safe_pearsonr(R, G)\n",
    "    corr_rb = safe_pearsonr(R, B)\n",
    "    corr_gb = safe_pearsonr(G, B)\n",
    "    \n",
    "    rgb_corr_mean = np.mean([corr_rg, corr_rb, corr_gb])\n",
    "    rgb_corr_std = np.std([corr_rg, corr_rb, corr_gb])\n",
    "\n",
    "    ycbcr = cv2.cvtColor(img_8bit, cv2.COLOR_RGB2YCrCb)\n",
    "    Y, Cr, Cb = cv2.split(ycbcr)  \n",
    "    \n",
    "    cb_kurt = safe_kurtosis(Cb.ravel())\n",
    "    cr_kurt = safe_kurtosis(Cr.ravel())\n",
    "\n",
    "    cb_lap = cv2.Laplacian(Cb.astype(np.float32), cv2.CV_32F, ksize=3)\n",
    "    cr_lap = cv2.Laplacian(Cr.astype(np.float32), cv2.CV_32F, ksize=3)\n",
    "\n",
    "    cb_lap = np.clip(cb_lap, -5000, 5000)\n",
    "    cr_lap = np.clip(cr_lap, -5000, 5000)\n",
    "\n",
    "    cb_residual_kurt = safe_kurtosis(cb_lap.ravel())\n",
    "    cr_residual_kurt = safe_kurtosis(cr_lap.ravel())\n",
    "\n",
    "    return {\n",
    "        'rgb_corr_mean': rgb_corr_mean,\n",
    "        'rgb_corr_std': rgb_corr_std,\n",
    "        'cb_kurtosis': cb_kurt,\n",
    "        'cr_kurtosis': cr_kurt,\n",
    "        'cb_residual_kurtosis': cb_residual_kurt,\n",
    "        'cr_residual_kurtosis': cr_residual_kurt\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5dd663",
   "metadata": {},
   "source": [
    "### Feature Family III: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c29f7d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_glcm_features(image, levels=64, distances=[1, 2, 4], angles=None):\n",
    "\n",
    "    if angles is None:\n",
    "        angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "\n",
    "    gray = cv2.cvtColor((image * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    gray_q = np.floor(gray / (256 / levels)).astype(np.uint8)\n",
    "\n",
    "    glcm = graycomatrix(\n",
    "        gray_q,\n",
    "        distances=distances,\n",
    "        angles=angles,\n",
    "        levels=levels,\n",
    "        symmetric=True,\n",
    "        normed=True\n",
    "    )\n",
    "\n",
    "    props = {}\n",
    "    for prop in ['contrast', 'homogeneity', 'energy', 'correlation']:\n",
    "        vals = graycoprops(glcm, prop)\n",
    "        props[prop] = np.mean(vals)\n",
    "\n",
    "    for k in props:\n",
    "        if np.isnan(props[k]) or np.isinf(props[k]):\n",
    "            props[k] = 0.0\n",
    "\n",
    "    return props"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9574187a",
   "metadata": {},
   "source": [
    "## Tabular Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0464bd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 1000/1000 [00:17<00:00, 57.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFT features shape: (1000, 4)\n",
      "Color features shape: (1000, 6)\n",
      "GLCM features shape: (1000, 4)\n",
      "NaN restantes: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fft_feature_list = []\n",
    "color_features_list = []\n",
    "glcm_feature_list = []\n",
    "\n",
    "for img in tqdm(X, desc=\"Extracting features\"):\n",
    "    fft = compute_fft_features(img)\n",
    "    color = compute_color_features(img)\n",
    "    texture = compute_glcm_features(img)\n",
    "\n",
    "    fft_feature_list.append(list(fft.values()))\n",
    "    color_features_list.append(list(color.values()))\n",
    "    glcm_feature_list.append(list(texture.values()))\n",
    "\n",
    "fft_features = np.array(fft_feature_list)\n",
    "color_features = np.array(color_features_list)\n",
    "texture_features = np.array(glcm_feature_list)\n",
    "\n",
    "fft_features = np.nan_to_num(fft_features, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "color_features = np.nan_to_num(color_features, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "texture_features = np.nan_to_num(texture_features, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "print(f\"FFT features shape: {fft_features.shape}\")\n",
    "print(f\"Color features shape: {color_features.shape}\")\n",
    "print(f\"GLCM features shape: {texture_features.shape}\")\n",
    "print(\"NaN restantes:\", np.isnan(texture_features).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bfca39b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (1000, 14)\n"
     ]
    }
   ],
   "source": [
    "X_features = np.concatenate([fft_features, color_features, texture_features], axis=1)\n",
    "\n",
    "print(f\"Feature matrix shape: {X_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "da548651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset tabular creado y guardado en 'image_features_dataset.csv'\n",
      "   radial_power_spectrum_mean  spectral_slope  spectral_flatness  \\\n",
      "0                63553.043900       -2.032502           0.011904   \n",
      "1                72022.384206       -2.275228           0.016276   \n",
      "2                44560.433672       -2.825358           0.005280   \n",
      "3                96580.610755       -2.394801           0.007560   \n",
      "4                46259.113538       -2.570078           0.008452   \n",
      "\n",
      "   high_freq_ratio  rgb_corr_mean  rgb_corr_std  cb_kurtosis  cr_kurtosis  \\\n",
      "0         0.001163       0.980505      0.011808     5.466961     3.621634   \n",
      "1         0.001194       0.961580      0.022610     3.250981     3.333180   \n",
      "2         0.000199       0.934480      0.040921     7.161317     5.584515   \n",
      "3         0.000367       0.731766      0.180140     3.528350     3.422427   \n",
      "4         0.000408       0.804772      0.011807     3.416708     2.300165   \n",
      "\n",
      "   cb_residual_kurtosis  cr_residual_kurtosis    contrast  homogeneity  \\\n",
      "0              9.074665              9.887692   59.531152     0.248598   \n",
      "1              5.072375              4.183186  166.515205     0.143565   \n",
      "2             24.704260             26.598431   44.746195     0.527432   \n",
      "3             13.744171              9.093219   91.022941     0.324718   \n",
      "4              8.352016              6.609596   57.802926     0.389486   \n",
      "\n",
      "     energy  correlation  label  \n",
      "0  0.051675     0.862839      1  \n",
      "1  0.036472     0.720742      1  \n",
      "2  0.143635     0.872957      1  \n",
      "3  0.055266     0.842738      1  \n",
      "4  0.064996     0.831024      1  \n"
     ]
    }
   ],
   "source": [
    "fft_cols = list(fft.keys())\n",
    "color_cols = list(color.keys())\n",
    "texture_cols = list(texture.keys())\n",
    "\n",
    "columns = fft_cols + color_cols + texture_cols\n",
    "\n",
    "df_features = pd.DataFrame(X_features, columns=columns)\n",
    "df_features['label'] = y\n",
    "\n",
    "df_features.to_csv(\"image_features_dataset.csv\", index=False)\n",
    "print(\"✅ Dataset tabular creado y guardado en 'image_features_dataset.csv'\")\n",
    "print(df_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07312b0b",
   "metadata": {},
   "source": [
    "## Train/Test Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e333193c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7549c330",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
