{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7eefa98",
   "metadata": {},
   "source": [
    "# Detecting Midjourney Images via Feature Engineering & Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb24925b",
   "metadata": {},
   "source": [
    "**Objectives**\n",
    "\n",
    "- **Engineer Discriminative Features**\n",
    "    Develop and extract features that effectively separate Stable Diffusion (AI-generated) images from authentic camera-captured photos using frequency, color, and texture analysis\n",
    "\n",
    "- **Build Reproducible Pipeline**\n",
    "\n",
    "    Construct a robust feature extraction pipeline that generates a tabular dataset suitable for ML. Ensure consistency and reproducibility across experiments.\n",
    "\n",
    "- **Train & Evaluate Classifiers**\n",
    "\n",
    "    Implement a classifier architectures such as Random Forest, XGBoost, SVM or Neural Networks. Rigorously evaluate performance using industry-standard metrics and confusion matrices\n",
    "\n",
    "- **Quantify Feature Relevance**\n",
    "\n",
    "    Apply multiple interpretability techniques such as Gini importance. Permutation importance, and SHAP values to understand which features drive classification decisions.\n",
    "\n",
    "\n",
    "**Dataset Structure**\n",
    "```bash\n",
    "imagenet_midjourney/\n",
    "|----test/ \n",
    "| |----ai/ \n",
    "| | |--[AI-generated images] (Stable Diffusion/Midjourney) \n",
    "| | Label: 1 (fake) \n",
    "| |----nature/ \n",
    "| | |--[Natural camera images] \n",
    "| | (Non-AI photographs) \n",
    "| | Label: 0 (real)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861f9abb",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7baac7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from skimage import io, color, img_as_ubyte\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy.stats import linregress, gmean, pearsonr, kurtosis\n",
    "\n",
    "DATASET_DIR = \"imagenet_midjourney/test\"\n",
    "\n",
    "CATEGORIES = {\n",
    "    \"ai\": 1,\n",
    "    \"nature\": 0\n",
    "}\n",
    "\n",
    "IMG_SIZE = (256, 256)\n",
    "COLOR_MODE = 'rgb'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c34c2c",
   "metadata": {},
   "source": [
    "## Image Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b150ef53",
   "metadata": {},
   "source": [
    "Load images from dataset directories, normalize formats, and prepare for feature extraction. Handle various input formats consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e64392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_images(base_dir, categories, img_size=(256, 256), color_mode='rgb'):\n",
    "    X, y, paths = [], [], []\n",
    "\n",
    "    for category, label in categories.items():\n",
    "        folder = os.path.join(base_dir, category)\n",
    "        if not os.path.exists(folder):\n",
    "            print(f\"Folder not encountered: {folder}\")\n",
    "            continue\n",
    "\n",
    "        for filename in tqdm(os.listdir(folder), desc=f\"Loading {category}\"):\n",
    "            file_path = os.path.join(folder, filename)\n",
    "\n",
    "            if not filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.webp')):\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                image = io.imread(file_path)\n",
    "\n",
    "                if color_mode == 'rgb':\n",
    "                    if image.ndim == 2:\n",
    "                        image = color.gray2rgb(image)\n",
    "                    elif image.shape[2] == 4:\n",
    "                        image = color.rgba2rgb(image)\n",
    "                elif color_mode == 'gray':\n",
    "                    image = color.rgb2gray(image)\n",
    "\n",
    "                image = cv2.resize(img_as_ubyte(image), img_size)\n",
    "\n",
    "                image = image.astype(np.float32) / 255.0\n",
    "\n",
    "                X.append(image)\n",
    "                y.append(label)\n",
    "                paths.append(file_path)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y, paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e8bfaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading ai: 100%|██████████| 500/500 [00:17<00:00, 28.03it/s]\n",
      "Loading nature: 100%|██████████| 500/500 [00:02<00:00, 196.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total imágenes cargadas: 1000\n",
      "Dimensión de ejemplo: (256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "X, y, image_paths = load_and_preprocess_images(DATASET_DIR, CATEGORIES, IMG_SIZE, COLOR_MODE)\n",
    "\n",
    "print(f\"Total imágenes cargadas: {len(X)}\")\n",
    "print(f\"Dimensión de ejemplo: {X[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e11400",
   "metadata": {},
   "source": [
    "## Feature Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca318ba",
   "metadata": {},
   "source": [
    "Extract per-image features across frequency, color, and texture domains. Generate comprehensive feature vectors for each sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51269539",
   "metadata": {},
   "source": [
    "### Feature Family I: Frequency & Spectrum Analysis (FFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9aee6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fft_features(image):\n",
    "    gray = cv2.cvtColor((image * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "    gray = gray.astype(np.float32) / 255.0\n",
    "\n",
    "    fft2 = np.fft.fft2(gray)\n",
    "    fshift = np.fft.fftshift(fft2)\n",
    "    magnitude_spectrum = np.abs(fshift) ** 2\n",
    "\n",
    "    rows, cols = gray.shape\n",
    "    crow, ccol = rows // 2, cols // 2\n",
    "    y, x = np.ogrid[:rows, :cols]\n",
    "    radius = np.sqrt((x - ccol) ** 2 + (y - crow) ** 2).astype(np.int32)\n",
    "\n",
    "    radial_profile = np.bincount(radius.ravel(), magnitude_spectrum.ravel()) / np.bincount(radius.ravel())\n",
    "    radial_profile = radial_profile[1:]\n",
    "\n",
    "    radial_power_spectrum_mean = np.mean(radial_profile)\n",
    "\n",
    "    freqs = np.arange(1, len(radial_profile) + 1)\n",
    "    log_freqs = np.log(freqs)\n",
    "    log_power = np.log(radial_profile + 1e-8)\n",
    "    slope, intercept, _, _, _ = linregress(log_freqs, log_power)\n",
    "    spectral_slope = slope\n",
    "\n",
    "    spectral_flatness = gmean(radial_profile + 1e-8) / (np.mean(radial_profile) + 1e-8)\n",
    "\n",
    "    cutoff = len(radial_profile) // 3\n",
    "    high_freq_energy = np.sum(radial_profile[-cutoff:])\n",
    "    total_energy = np.sum(radial_profile)\n",
    "    high_freq_ratio = high_freq_energy / (total_energy + 1e-8)\n",
    "\n",
    "    return {\n",
    "        'radial_power_spectrum_mean': radial_power_spectrum_mean,\n",
    "        'spectral_slope': spectral_slope,\n",
    "        'spectral_flatness': spectral_flatness,\n",
    "        'high_freq_ratio': high_freq_ratio\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b6f555",
   "metadata": {},
   "source": [
    "### Feature Family II: Colo & Chrominance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33cf45a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_pearsonr(a, b):\n",
    "    if np.std(a) < 1e-8 or np.std(b) < 1e-8:\n",
    "        return 0.0\n",
    "    r, _ = pearsonr(a, b)\n",
    "    return np.nan_to_num(r, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "def safe_kurtosis(x):\n",
    "    if x.size == 0 or np.allclose(x, x.flat[0], atol=1e-8) or np.std(x) < 1e-8:\n",
    "        return 0.0\n",
    "    val = kurtosis(x, fisher=False)\n",
    "    return np.nan_to_num(val, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "def compute_color_features(image):\n",
    "    img_8bit = (image * 255).astype(np.uint8)\n",
    "\n",
    "    R = img_8bit[:, :, 0].astype(np.float32).ravel()\n",
    "    G = img_8bit[:, :, 1].astype(np.float32).ravel()\n",
    "    B = img_8bit[:, :, 2].astype(np.float32).ravel()\n",
    "\n",
    "    corr_rg = safe_pearsonr(R, G)\n",
    "    corr_rb = safe_pearsonr(R, B)\n",
    "    corr_gb = safe_pearsonr(G, B)\n",
    "    \n",
    "    rgb_corr_mean = np.mean([corr_rg, corr_rb, corr_gb])\n",
    "    rgb_corr_std = np.std([corr_rg, corr_rb, corr_gb])\n",
    "\n",
    "    ycbcr = cv2.cvtColor(img_8bit, cv2.COLOR_RGB2YCrCb)\n",
    "    Y, Cr, Cb = cv2.split(ycbcr)  \n",
    "    \n",
    "    cb_kurt = safe_kurtosis(Cb.ravel())\n",
    "    cr_kurt = safe_kurtosis(Cr.ravel())\n",
    "\n",
    "    cb_lap = cv2.Laplacian(Cb.astype(np.float32), cv2.CV_32F, ksize=3)\n",
    "    cr_lap = cv2.Laplacian(Cr.astype(np.float32), cv2.CV_32F, ksize=3)\n",
    "\n",
    "    cb_lap = np.clip(cb_lap, -5000, 5000)\n",
    "    cr_lap = np.clip(cr_lap, -5000, 5000)\n",
    "\n",
    "    cb_residual_kurt = safe_kurtosis(cb_lap.ravel())\n",
    "    cr_residual_kurt = safe_kurtosis(cr_lap.ravel())\n",
    "\n",
    "    return {\n",
    "        'rgb_corr_mean': rgb_corr_mean,\n",
    "        'rgb_corr_std': rgb_corr_std,\n",
    "        'cb_kurtosis': cb_kurt,\n",
    "        'cr_kurtosis': cr_kurt,\n",
    "        'cb_residual_kurtosis': cb_residual_kurt,\n",
    "        'cr_residual_kurtosis': cr_residual_kurt\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5dd663",
   "metadata": {},
   "source": [
    "### Feature Family III: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9574187a",
   "metadata": {},
   "source": [
    "## Tabular Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0464bd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 1000/1000 [00:12<00:00, 80.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFT features shape: (1000, 4)\n",
      "Color features shape: (1000, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fft_feature_list = []\n",
    "color_features_list = []\n",
    "\n",
    "for img in tqdm(X, desc=\"Extracting features\"):\n",
    "    fft = compute_fft_features(img)\n",
    "    color = compute_color_features(img)\n",
    "\n",
    "    fft_feature_list.append(list(fft.values()))\n",
    "    color_features_list.append(list(color.values()))\n",
    "\n",
    "fft_features = np.array(fft_feature_list)\n",
    "color_features = np.array(color_features_list)\n",
    "\n",
    "print(f\"FFT features shape: {fft_features.shape}\")\n",
    "print(f\"Color features shape: {color_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e369be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features de la imagen 0:\n",
      "[ 6.35530439e+04 -2.03250235e+00  1.19042791e-02  1.16264812e-03]\n",
      "[0.98050547 0.01180802 5.46696074 3.62163393 9.07466507 9.88769245]\n",
      "\n",
      "Features de la imagen 999:\n",
      "[ 1.26320369e+05 -2.37458115e+00  5.31084599e-03  3.31846399e-04]\n",
      "[0.9999969 0.        0.        0.        0.        0.       ]\n",
      "NaN restantes: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Features de la imagen 0:\")\n",
    "print(fft_features[0])\n",
    "print(color_features[0])\n",
    "\n",
    "# Mostrar las features de la imagen 999\n",
    "print(\"\\nFeatures de la imagen 999:\")\n",
    "print(fft_features[999])\n",
    "print(color_features[999])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7549c330",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
