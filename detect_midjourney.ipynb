{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7eefa98",
   "metadata": {},
   "source": [
    "# Detecting Midjourney Images via Feature Engineering & Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb24925b",
   "metadata": {},
   "source": [
    "**Objectives**\n",
    "\n",
    "- **Engineer Discriminative Features**\n",
    "    Develop and extract features that effectively separate Stable Diffusion (AI-generated) images from authentic camera-captured photos using frequency, color, and texture analysis\n",
    "\n",
    "- **Build Reproducible Pipeline**\n",
    "\n",
    "    Construct a robust feature extraction pipeline that generates a tabular dataset suitable for ML. Ensure consistency and reproducibility across experiments.\n",
    "\n",
    "- **Train & Evaluate Classifiers**\n",
    "\n",
    "    Implement a classifier architectures such as Random Forest, XGBoost, SVM or Neural Networks. Rigorously evaluate performance using industry-standard metrics and confusion matrices\n",
    "\n",
    "- **Quantify Feature Relevance**\n",
    "\n",
    "    Apply multiple interpretability techniques such as Gini importance. Permutation importance, and SHAP values to understand which features drive classification decisions.\n",
    "\n",
    "\n",
    "**Dataset Structure**\n",
    "```bash\n",
    "imagenet_midjourney/\n",
    "|----test/ \n",
    "| |----ai/ \n",
    "| | |--[AI-generated images] (Stable Diffusion/Midjourney) \n",
    "| | Label: 1 (fake) \n",
    "| |----nature/ \n",
    "| | |--[Natural camera images] \n",
    "| | (Non-AI photographs) \n",
    "| | Label: 0 (real)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861f9abb",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7baac7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from skimage import io, color, img_as_ubyte\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy.stats import linregress, gmean\n",
    "\n",
    "DATASET_DIR = \"imagenet_midjourney/test\"\n",
    "\n",
    "CATEGORIES = {\n",
    "    \"ai\": 1,\n",
    "    \"nature\": 0\n",
    "}\n",
    "\n",
    "IMG_SIZE = (256, 256)\n",
    "COLOR_MODE = 'rgb'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c34c2c",
   "metadata": {},
   "source": [
    "## Image Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b150ef53",
   "metadata": {},
   "source": [
    "Load images from dataset directories, normalize formats, and prepare for feature extraction. Handle various input formats consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e64392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_images(base_dir, categories, img_size=(256, 256), color_mode='rgb'):\n",
    "    X, y, paths = [], [], []\n",
    "\n",
    "    for category, label in categories.items():\n",
    "        folder = os.path.join(base_dir, category)\n",
    "        if not os.path.exists(folder):\n",
    "            print(f\"Folder not encountered: {folder}\")\n",
    "            continue\n",
    "\n",
    "        for filename in tqdm(os.listdir(folder), desc=f\"Loading {category}\"):\n",
    "            file_path = os.path.join(folder, filename)\n",
    "\n",
    "            if not filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.webp')):\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                image = io.imread(file_path)\n",
    "\n",
    "                if color_mode == 'rgb':\n",
    "                    if image.ndim == 2:\n",
    "                        image = color.gray2rgb(image)\n",
    "                    elif image.shape[2] == 4:\n",
    "                        image = color.rgba2rgb(image)\n",
    "                elif color_mode == 'gray':\n",
    "                    image = color.rgb2gray(image)\n",
    "\n",
    "                image = cv2.resize(img_as_ubyte(image), img_size)\n",
    "\n",
    "                image = image.astype(np.float32) / 255.0\n",
    "\n",
    "                X.append(image)\n",
    "                y.append(label)\n",
    "                paths.append(file_path)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y, paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e8bfaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading ai: 100%|██████████| 500/500 [00:17<00:00, 28.03it/s]\n",
      "Loading nature: 100%|██████████| 500/500 [00:02<00:00, 196.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total imágenes cargadas: 1000\n",
      "Dimensión de ejemplo: (256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "X, y, image_paths = load_and_preprocess_images(DATASET_DIR, CATEGORIES, IMG_SIZE, COLOR_MODE)\n",
    "\n",
    "print(f\"Total imágenes cargadas: {len(X)}\")\n",
    "print(f\"Dimensión de ejemplo: {X[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e11400",
   "metadata": {},
   "source": [
    "## Feature Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca318ba",
   "metadata": {},
   "source": [
    "Extract per-image features across frequency, color, and texture domains. Generate comprehensive feature vectors for each sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51269539",
   "metadata": {},
   "source": [
    "### Feature Family I: Frequency & Spectrum Analysis (FFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9aee6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fft_features(image):\n",
    "    gray = cv2.cvtColor((image * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "    gray = gray.astype(np.float32) / 255.0\n",
    "\n",
    "    fft2 = np.fft.fft2(gray)\n",
    "    fshift = np.fft.fftshift(fft2)\n",
    "    magnitude_spectrum = np.abs(fshift) ** 2\n",
    "\n",
    "    rows, cols = gray.shape\n",
    "    crow, ccol = rows // 2, cols // 2\n",
    "    y, x = np.ogrid[:rows, :cols]\n",
    "    radius = np.sqrt((x - ccol) ** 2 + (y - crow) ** 2).astype(np.int32)\n",
    "\n",
    "    radial_profile = np.bincount(radius.ravel(), magnitude_spectrum.ravel()) / np.bincount(radius.ravel())\n",
    "    radial_profile = radial_profile[1:]\n",
    "\n",
    "    radial_power_spectrum_mean = np.mean(radial_profile)\n",
    "\n",
    "    freqs = np.arange(1, len(radial_profile) + 1)\n",
    "    log_freqs = np.log(freqs)\n",
    "    log_power = np.log(radial_profile + 1e-8)\n",
    "    slope, intercept, _, _, _ = linregress(log_freqs, log_power)\n",
    "    spectral_slope = slope\n",
    "\n",
    "    spectral_flatness = gmean(radial_profile + 1e-8) / (np.mean(radial_profile) + 1e-8)\n",
    "\n",
    "    cutoff = len(radial_profile) // 3\n",
    "    high_freq_energy = np.sum(radial_profile[-cutoff:])\n",
    "    total_energy = np.sum(radial_profile)\n",
    "    high_freq_ratio = high_freq_energy / (total_energy + 1e-8)\n",
    "\n",
    "    return {\n",
    "        'radial_power_spectrum_mean': radial_power_spectrum_mean,\n",
    "        'spectral_slope': spectral_slope,\n",
    "        'spectral_flatness': spectral_flatness,\n",
    "        'high_freq_ratio': high_freq_ratio\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9574187a",
   "metadata": {},
   "source": [
    "## Tabular Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0464bd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 1000/1000 [00:04<00:00, 222.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFT features shape: (1000, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fft_feature_list = []\n",
    "\n",
    "for img in tqdm(X, desc=\"Extracting features\"):\n",
    "    features = compute_fft_features(img)\n",
    "    fft_feature_list.append(list(features.values()))\n",
    "\n",
    "fft_features = np.array(fft_feature_list)\n",
    "\n",
    "print(f\"FFT features shape: {fft_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7549c330",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
